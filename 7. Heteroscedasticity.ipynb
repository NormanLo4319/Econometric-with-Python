{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "gorgeous-reach",
   "metadata": {},
   "source": [
    "## Heteroscedasticity\n",
    "\n",
    "The homoscedasticity assumptions SLR.5 for the simple linear regression model and MLR.5 for the multiple linear regression model require that the variance of the error terms is unrelated to the regresssors, i.e.\n",
    "\n",
    "$$Var(u|x_1, x_2, ..., x_k) = \\sigma^2$$\n",
    "\n",
    "Unbaisedness and consistency (Theorems 3.1, 5.1) do not depend on this assumption, but the sampling distribution (Theorems 3.2, 4.1, 5.2) does. If homoscedasticity is violated, the standard errors are invalid and all inferences form *t*, *F*, and other tests based on them are unreliable. Also the (asymptotic) efficiency of the OLS (Theorems 3.4, 5.3) depends on homoscedasticity. Generally, homoscedasticity is difficult to justify from theory. Different kinds of individiuals might have different amounts of unobserved influences in ways that depend on regressors.\n",
    "\n",
    "We cover three topics in this notebook: First, we show how the formula of the estimated variance-covariance can be adjusted so it does not require homoscedasticity. In this way, we can use OLS to get unbaised and consistent parameter estimates and draw inference from valid standard errors and tests. Next, we present tests for the existence of heteroscedasticity. Finally, we discusses weighted least squares (WLS) as an alternative to OLS. This estimator can be more efficient in the presence fo heteroscedasticity. \n",
    "\n",
    "\n",
    "**Topics:**\n",
    "\n",
    "1. Heteroscedasticity - Robust Inference  \n",
    "2. Heteroscedasticity Tests  \n",
    "3. Weighted Least Squares  \n",
    "\n",
    "### 1. Heteroscedasticity - Robust Inference\n",
    "\n",
    "Wooldridge (2019, Section 8.2) presents formulas for heteroscedasticity-robust standard errors. In **statsmodels**, an easy way to do these calculations is to make use of the argument **cov_type** in the method **fit()**. The argument **cov_type** can produce several refined versions of the White formula presented by Wooldridge (2019).\n",
    "\n",
    "If the regression model obtained by **ols** is stored in the variable **reg**, the variance-covariance matrix can be calculated using\n",
    "\n",
    "- **reg.fit(cov_type='nonrobust')** or **reg.fit()** for the default homoscedasticity-based standard errors.\n",
    "- **reg.fit(cov_type='HC0')** for the classical version of White's robust variance-covariance matrix presented by Wooldridge (2019, Equation 8.4 in Section 8.2).\n",
    "- **reg.fit(cov_type='HC1')** for a version of White's robust variance-covariance matrix corrected by degree of freedom.\n",
    "- **reg.fit(cov_type='HC2')** for a version with a small sample correction. This is the default behaviro of Stata.\n",
    "- **reg.fit(cov_type='HC3')** for the refined version of White's' robust variance-covariance matrix.\n",
    "\n",
    "Regression tables with coefficents, standard errors, *t* statistics, and their *p* values are based on the specified method of variance-covariance estimation. To perform *F* tests of a joint hypothesis for an estimated model the syntax is the same as presented in the previous notebooks.\n",
    "\n",
    "#### Wooldridge, Example 8.2: Heteroscedasticity - Robust Inference\n",
    "\n",
    "We use two example to demonstrate these commands. **results_default** and **results_white** use the usual standard error and the classical White standard errors respectively. This reproduces standard errors reported in Wooldridge (2019)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "natural-preserve",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import wooldridge as woo\n",
    "import pandas as pd \n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cleared-tuning",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data set 'gpa3'\n",
    "gpa3 = woo.dataWoo('gpa3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ongoing-photograph",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define regression model\n",
    "reg = smf.ols(formula = 'cumgpa ~ sat + hsperc + tothrs + female + black + white',\n",
    "             data = gpa3, subset = gpa3['spring'] == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "front-messenger",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression Table (Default SE): \n",
      "            Betas  Standarde Errors  t Statistics  p Value\n",
      "Intercept  1.4701            0.2298        6.3971   0.0000\n",
      "sat        0.0011            0.0002        6.3885   0.0000\n",
      "hsperc    -0.0086            0.0012       -6.9060   0.0000\n",
      "tothrs     0.0025            0.0007        3.4255   0.0007\n",
      "female     0.3034            0.0590        5.1412   0.0000\n",
      "black     -0.1283            0.1474       -0.8705   0.3846\n",
      "white     -0.0587            0.1410       -0.4165   0.6773\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Estimate default model (only for spring data)\n",
    "results_default = reg.fit()\n",
    "\n",
    "# Print regression table\n",
    "table_default = pd.DataFrame({'Betas': round(results_default.params, 4),\n",
    "                     'Standarde Errors': round(results_default.bse, 4),\n",
    "                     't Statistics': round(results_default.tvalues, 4),\n",
    "                     'p Value': round(results_default.pvalues, 4)})\n",
    "print(f'Regression Table (Default SE): \\n{table_default}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "timely-turning",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression Table (Classical White SE): \n",
      "            Betas  Standarde Errors  t Statistics  p Value\n",
      "Intercept  1.4701            0.2186        6.7261   0.0000\n",
      "sat        0.0011            0.0002        6.0136   0.0000\n",
      "hsperc    -0.0086            0.0014       -6.1001   0.0000\n",
      "tothrs     0.0025            0.0007        3.4136   0.0006\n",
      "female     0.3034            0.0586        5.1807   0.0000\n",
      "black     -0.1283            0.1181       -1.0863   0.2774\n",
      "white     -0.0587            0.1103       -0.5323   0.5945\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Estimate model with White SE (only for spring data)\n",
    "results_white = reg.fit(cov_type = 'HC0')\n",
    "\n",
    "# Print regression table\n",
    "table_white = pd.DataFrame({'Betas': round(results_white.params, 4),\n",
    "                     'Standarde Errors': round(results_white.bse, 4),\n",
    "                     't Statistics': round(results_white.tvalues, 4),\n",
    "                     'p Value': round(results_white.pvalues, 4)})\n",
    "print(f'Regression Table (Classical White SE): \\n{table_white}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "minimal-lebanon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression Table (Refined White SE): \n",
      "            Betas  Standarde Errors  t Statistics  p Value\n",
      "Intercept  1.4701            0.2294        6.4089   0.0000\n",
      "sat        0.0011            0.0002        5.8402   0.0000\n",
      "hsperc    -0.0086            0.0014       -5.9341   0.0000\n",
      "tothrs     0.0025            0.0007        3.3418   0.0008\n",
      "female     0.3034            0.0600        5.0539   0.0000\n",
      "black     -0.1283            0.1282       -1.0007   0.3170\n",
      "white     -0.0587            0.1204       -0.4876   0.6258\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Estimate model with refined White SE (only for spring data)\n",
    "results_refined = reg.fit(cov_type = 'HC3')\n",
    "\n",
    "# Print regression table\n",
    "table_refined = pd.DataFrame({'Betas': round(results_refined.params, 4),\n",
    "                     'Standarde Errors': round(results_refined.bse, 4),\n",
    "                     't Statistics': round(results_refined.tvalues, 4),\n",
    "                     'p Value': round(results_refined.pvalues, 4)})\n",
    "print(f'Regression Table (Refined White SE): \\n{table_refined}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "biblical-hardware",
   "metadata": {},
   "source": [
    "For the *F* tests, three versions are calculated and diplayed. The results generally do not differ a lot between the different versions. This is an indication that heteroscedasticity might not be a big issue in this example. To be sure, we would like to have a formal test as discussed in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "exciting-collaboration",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import wooldridge as woo\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "solved-faith",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data set 'gpa3'\n",
    "gpa3 = woo.dataWoo('gpa3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "disturbed-reverse",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define regression model\n",
    "reg = smf.ols(formula = 'cumgpa ~ sat + hsperc + tothrs + female + black + white',\n",
    "             data = gpa3, subset = gpa3['spring'] == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "occupational-tractor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hypotheses for testing\n",
    "hypotheses = ['black = 0', 'white = 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "meaningful-cisco",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F Statistic: (Default VCOV) \n",
      "0.6796041956073353\n",
      "\n",
      "F Test p-value: (Default VCOV) \n",
      "0.5074683622584049\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# F-test using differetn variance-covariance formulas\n",
    "# Default VCOV:\n",
    "results_default = reg.fit()\n",
    "ftest_default = results_default.f_test(hypotheses)\n",
    "fstat_default = ftest_default.statistic[0][0]\n",
    "fpval_default = ftest_default.pvalue\n",
    "print(f'F Statistic: (Default VCOV) \\n{fstat_default}\\n')\n",
    "print(f'F Test p-value: (Default VCOV) \\n{fpval_default}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "earlier-agriculture",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F Statistic: (Classical White VCOV) \n",
      "0.7477969818036153\n",
      "\n",
      "F Test p-value: (Classical White VCOV) \n",
      "0.4741442714738484\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classical White VCOV:\n",
    "results_hc0 = reg.fit(cov_type = 'HC0')\n",
    "ftest_hc0 = results_hc0.f_test(hypotheses)\n",
    "fstat_hc0 = ftest_hc0.statistic[0][0]\n",
    "fpval_hc0 = ftest_hc0.pvalue\n",
    "print(f'F Statistic: (Classical White VCOV) \\n{fstat_hc0}\\n')\n",
    "print(f'F Test p-value: (Classical White VCOV) \\n{fpval_hc0}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "mexican-secretariat",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F Statistic: (Refined White VCOV) \n",
      "0.6724692957656578\n",
      "\n",
      "F Test p-value: (Refined White VCOV) \n",
      "0.5110883633440992\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Refined White VCOV:\n",
    "results_hc3 = reg.fit(cov_type = 'HC3')\n",
    "ftest_hc3 = results_hc3.f_test(hypotheses)\n",
    "fstat_hc3 = ftest_hc3.statistic[0][0]\n",
    "fpval_hc3 = ftest_hc3.pvalue\n",
    "print(f'F Statistic: (Refined White VCOV) \\n{fstat_hc3}\\n')\n",
    "print(f'F Test p-value: (Refined White VCOV) \\n{fpval_hc3}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "motivated-mounting",
   "metadata": {},
   "source": [
    "### 2. Heteroscedasticity Tests\n",
    "\n",
    "The Breusch-pagan (BP) test for heteroscedasticity is easy to implement with basic OLS routines. After a model\n",
    "\n",
    "$$y=\\beta_0+\\beta_1x_1+...+\\beta_kx_k+u$$\n",
    "\n",
    "is estimated, we obtain the residuals $\\hat{u_i}$ for all observations *i* = 1, 2, 3, ..., *n*. We regress their squared value on all independent variables from the orginal equation. We can either look at the standard *F* test of overall significance preinted for example by the **summary()** method. Or we can use an *LM* test by multiplying the $R^2$ from the second regression with the number of observations.\n",
    "\n",
    "In **statsmodels**, this is easily done. Remember that the residuals from a regression are saved as **resid** in the result object that is returned by **fit()**. Their squared value can be stored in a new variable to be used as a dependent variable in the second stage.\n",
    "\n",
    "The *LM* version of the BP test is even more convenient to use with the **statsmodels** function **stats.diagnostic.het_breuschpagan()**. It can be used directly as demonstrated in our example to compute the test statistic and corresponding *p* value.\n",
    "\n",
    "#### Wooldrdge, Example 8.4: Heteroscedasticity in a Housing Price Equation\n",
    "\n",
    "We implement the *F* and *LM* versions of the BP test. The command **stats.diagnostic.het_breuschpagan()** simply takes the regression residuals and the regressor matrix as an argument and delivers a test statistic of *LM* = 14.09. The corresponding *p* value is smaller than 0.003 so we reject homoscedasticity for all reasonable signficance levels.\n",
    "\n",
    "The output also shows the manual implementation of a second stage regression where we regress squared residuals on the independent variables. We can directly interpret the reported *F* statistic of 5.34 and its *p* value of 0.002 as the *F* version of the BP test. We can manually calculate the *LM* statistic by multiplying the reported $R^2$ = 0.16 with the number of observation *n* = 88.\n",
    "\n",
    "We replicate the test for an alternative model with logarithms discussed by Wooldridge (2019) together with the White test in the example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "strategic-month",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import wooldridge as woo\n",
    "import pandas as pd \n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import patsy as pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "painful-programming",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data set 'hprice1'\n",
    "hprice1 = woo.dataWoo('hprice1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "electronic-tunnel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression Table (Default SE): \n",
      "             Betas  Standarde Errors  t Statistics  p Value\n",
      "Intercept -21.7703           29.4750       -0.7386   0.4622\n",
      "lotsize     0.0021            0.0006        3.2201   0.0018\n",
      "sqrft       0.1228            0.0132        9.2751   0.0000\n",
      "bdrms      13.8525            9.0101        1.5374   0.1279\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Estimate model:\n",
    "reg = smf.ols(formula = 'price ~ lotsize + sqrft + bdrms',\n",
    "             data = hprice1)\n",
    "results = reg.fit()\n",
    "\n",
    "# Print regression table\n",
    "table_results = pd.DataFrame({'Betas': round(results.params, 4),\n",
    "                     'Standarde Errors': round(results.bse, 4),\n",
    "                     't Statistics': round(results.tvalues, 4),\n",
    "                     'p Value': round(results.pvalues, 4)})\n",
    "print(f'Regression Table (Default SE): \\n{table_results}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "stable-trademark",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BP Test LM Statistic: 14.092385504350242\n",
      "\n",
      "BP Test LM p-value: 0.0027820595556890867\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Automatic BP test (LM version)\n",
    "y, X = pt.dmatrices('price ~ lotsize + sqrft + bdrms',\n",
    "                   data = hprice1, return_type = 'dataframe')\n",
    "result_bp_lm = sm.stats.diagnostic.het_breuschpagan(results.resid, X)\n",
    "bp_lm_statistic = result_bp_lm[0]\n",
    "bp_lm_pval = result_bp_lm[1]\n",
    "print(f'BP Test LM Statistic: {bp_lm_statistic}\\n')\n",
    "print(f'BP Test LM p-value: {bp_lm_pval}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "christian-cloud",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BP Test F Statistic: 5.338919363241419\n",
      "\n",
      "BP Test p-value: 0.0020477444209360787\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Manual BP test (F version)\n",
    "hprice1['resid_sq'] = results.resid ** 2\n",
    "reg_resid = smf.ols(formula = 'resid_sq ~ lotsize + sqrft + bdrms',\n",
    "                   data = hprice1)\n",
    "results_resid = reg_resid.fit()\n",
    "bp_F_statistic = results_resid.fvalue\n",
    "bp_F_pval = results_resid.f_pvalue\n",
    "print(f'BP Test F Statistic: {bp_F_statistic}\\n')\n",
    "print(f'BP Test p-value: {bp_F_pval}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "celtic-magnitude",
   "metadata": {},
   "source": [
    "The White test is a variant of the BP test where in the second stage, we do not regress the squared first-stage residuals on the original regressors only. Instead, we add interactions and polynomials of them or include the fitted value $\\hat{y}$ and $\\hat{y}^2$. This can easily be done in a manual second-stage regression remembering that the fitted values are stored in the regression results object as **fittedvalues**.\n",
    "\n",
    "Conveniently, we can also use the **stats.diagnostic.het_breuschpagan()** command to do the calculations of the *LM* version of hte test including the *p* values automatically. All we have to do is to explain that in the second stage we want to a different set of regressors.\n",
    "\n",
    "#### Wooldridge, Example 8.5: BP and White test in the Log Housing Price Equation\n",
    "\n",
    "We implements the BP and the White test for a model that now contains logarithms of the dependent variable and two independent variables. The LM versions of both the BP and the White test do not reject the null hypothesis at conventional signficiance levels with *p* values of 0.238 and 0.178, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "deadly-heart",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import wooldridge as woo\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import patsy as pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "seeing-merchandise",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data set 'hprice1'\n",
    "hprice1 = woo.dataWoo('hprice1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "tender-rolling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression Table (Default SE): \n",
      "                  Betas  Standarde Errors  t Statistics  p Value\n",
      "Intercept       -1.2970            0.6513       -1.9915   0.0497\n",
      "np.log(lotsize)  0.1680            0.0383        4.3877   0.0000\n",
      "np.log(sqrft)    0.7002            0.0929        7.5403   0.0000\n",
      "bdrms            0.0370            0.0275        1.3424   0.1831\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Estimate regression model\n",
    "reg = smf.ols(formula = 'np.log(price) ~ np.log(lotsize) + np.log(sqrft) + bdrms',\n",
    "             data = hprice1)\n",
    "results = reg.fit()\n",
    "\n",
    "# Print regression table\n",
    "table_results = pd.DataFrame({'Betas': round(results.params, 4),\n",
    "                     'Standarde Errors': round(results.bse, 4),\n",
    "                     't Statistics': round(results.tvalues, 4),\n",
    "                     'p Value': round(results.pvalues, 4)})\n",
    "print(f'Regression Table (Default SE): \\n{table_results}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "disturbed-dressing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BP Test LM Statistic: 4.223245741805276\n",
      "\n",
      "BP Test LM p-value: 0.23834482631492962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Automatic BP test (LM version)\n",
    "y, X_bp = pt.dmatrices('np.log(price) ~ np.log(lotsize) + np.log(sqrft) + bdrms',\n",
    "                   data = hprice1, return_type = 'dataframe')\n",
    "result_bp_lm = sm.stats.diagnostic.het_breuschpagan(results.resid, X_bp)\n",
    "bp_lm_statistic = result_bp_lm[0]\n",
    "bp_lm_pval = result_bp_lm[1]\n",
    "print(f'BP Test LM Statistic: {bp_lm_statistic}\\n')\n",
    "print(f'BP Test LM p-value: {bp_lm_pval}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "opposite-gardening",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White Test Statistic: 3.4472865468750546\n",
      "\n",
      "White Test p-value: 0.17841494794132906\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# White test\n",
    "X_wh = pd.DataFrame({'const':1, 'fitted_reg': results.fittedvalues,\n",
    "                    'fitted_reg_sq': results.fittedvalues ** 2})\n",
    "result_white = sm.stats.diagnostic.het_breuschpagan(results.resid, X_wh)\n",
    "white_statistic = result_white[0]\n",
    "white_pval = result_white[1]\n",
    "print(f'White Test Statistic: {white_statistic}\\n')\n",
    "print(f'White Test p-value: {white_pval}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exotic-bubble",
   "metadata": {},
   "source": [
    "### 3. Weighted Least Squares\n",
    "\n",
    "Weighted Least Squares (WLS) attempts to provide a more efficient alternative to OLS. It is a special version of a feasible generalized least squares (FGLS) estimator. Instead of the sum of squared residuals, their weighted sum is minimized. If the weights are inversely proportional to the variance, the estimator is efficient. Also the usual formula for the variance-covariance matrix of the parameter estimates and standard inference tools are valid.\n",
    "\n",
    "We can obtain WLS parameter estimates by multiplying each variable in the model with the square root of the weight as shown by Wooldridge (2019, Section 8.4). In **statsmodels**, it is more convenient to use the option **weights = ...** of hte command **wls()**. This provides a more concise syntax and takes care of the correct residuals, fitted values, predictions, and the like in terms of the original variables. In terms of methods and arguments, **wls()** is very similar to the function **ols()**.\n",
    "\n",
    "#### Wooldridge, Example 8.6: Financial Wealth Equation\n",
    "\n",
    "In this example, we implement both OLS and WLS estimation for a regression of financial wealth (**nettfa**) on income (**inc**), age (**age**), gender (**male**), and eligibility for a pension plan (**e401k**) using the data set *401ksubs*. Following Wooldridge (2019), we assume that the variance is proportional to the income variable **inc**. Therefore, the optimal weight is $\\frac{1}{inc}$ which is given as **wls_weight** in the **wls** call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "resistant-handy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import wooldridge as woo\n",
    "import pandas as pd \n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "promotional-delta",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data set '401ksubs'\n",
    "k401ksubs = woo.dataWoo('401ksubs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "returning-japan",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsetting data\n",
    "k401ksubs_sub = k401ksubs[k401ksubs['fsize'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "medieval-adjustment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression Table (OLS): \n",
      "                      Betas  Standarde Errors  t Statistics  p Value\n",
      "Intercept          -20.9850            3.4909       -6.0114   0.0000\n",
      "inc                  0.7706            0.0994        7.7486   0.0000\n",
      "I((age - 25) ** 2)   0.0251            0.0043        5.7912   0.0000\n",
      "male                 2.4779            2.0558        1.2053   0.2281\n",
      "e401k                6.8862            2.2837        3.0153   0.0026\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# OLS (only for singles, i.e. 'fsize' == 1)\n",
    "reg_ols = smf.ols(formula = 'nettfa ~ inc + I((age-25)**2) + male + e401k',\n",
    "                 data = k401ksubs_sub)\n",
    "results_ols = reg_ols.fit(cov_type = 'HC0')\n",
    "\n",
    "# Print regression table\n",
    "table_ols = pd.DataFrame({'Betas': round(results_ols.params, 4),\n",
    "                     'Standarde Errors': round(results_ols.bse, 4),\n",
    "                     't Statistics': round(results_ols.tvalues, 4),\n",
    "                     'p Value': round(results_ols.pvalues, 4)})\n",
    "print(f'Regression Table (OLS): \\n{table_ols}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ordered-republican",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression Table (WLS): \n",
      "                      Betas  Standarde Errors  t Statistics  p Value\n",
      "Intercept          -16.7025            1.9580       -8.5304   0.0000\n",
      "inc                  0.7404            0.0643       11.5140   0.0000\n",
      "I((age - 25) ** 2)   0.0175            0.0019        9.0796   0.0000\n",
      "male                 1.8405            1.5636        1.1771   0.2393\n",
      "e401k                5.1883            1.7034        3.0458   0.0024\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# WLS (only for singles, i.e. 'fsize' == 1)\n",
    "wls_weight = list(1 / k401ksubs_sub['inc'])\n",
    "reg_wls = smf.wls(formula = 'nettfa ~ inc + I((age-25)**2) + male + e401k',\n",
    "                 weights = wls_weight, data = k401ksubs_sub)\n",
    "results_wls = reg_wls.fit()\n",
    "\n",
    "# Print regression table\n",
    "table_wls = pd.DataFrame({'Betas': round(results_wls.params, 4),\n",
    "                     'Standarde Errors': round(results_wls.bse, 4),\n",
    "                     't Statistics': round(results_wls.tvalues, 4),\n",
    "                     'p Value': round(results_wls.pvalues, 4)})\n",
    "print(f'Regression Table (WLS): \\n{table_wls}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "violent-scale",
   "metadata": {},
   "source": [
    "We can also use heteroscedasticity-robust statistics to account for the fact that our variance function might be misspecified. Here we repeat the WLS estimation but reports non-robust and robust standard errors and *t* statistics. It replicates Wooldridge (2019, Table 8.2) with the only difference that we use a refined version of the robust SE formula. There is nothing special about the implementation. The fact that we used weights is correctly accounted for in the following calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "median-knowing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import wooldridge as woo\n",
    "import pandas as pd \n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "annoying-battle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data set '401ksubs'\n",
    "k401ksubs = woo.dataWoo('401ksubs')\n",
    "\n",
    "# Subsetting data\n",
    "k401ksubs_sub = k401ksubs[k401ksubs['fsize'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "wanted-composition",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WLS (only for singles, i.e. 'fsize' == 1)\n",
    "wls_weight = list(1 / k401ksubs_sub['inc'])\n",
    "reg_wls = smf.wls(formula = 'nettfa ~ inc + I((age-25)**2) + male + e401k',\n",
    "                 weights = wls_weight, data = k401ksubs_sub)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "consecutive-alarm",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression Table (Non-Robust SE): \n",
      "                      Betas  Standarde Errors  t Statistics  p Value\n",
      "Intercept          -16.7025            1.9580       -8.5304   0.0000\n",
      "inc                  0.7404            0.0643       11.5140   0.0000\n",
      "I((age - 25) ** 2)   0.0175            0.0019        9.0796   0.0000\n",
      "male                 1.8405            1.5636        1.1771   0.2393\n",
      "e401k                5.1883            1.7034        3.0458   0.0024\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Non-robust (default) results\n",
    "results_wls = reg_wls.fit()\n",
    "\n",
    "# Print regression table\n",
    "table_default = pd.DataFrame({'Betas': round(results_wls.params, 4),\n",
    "                     'Standarde Errors': round(results_wls.bse, 4),\n",
    "                     't Statistics': round(results_wls.tvalues, 4),\n",
    "                     'p Value': round(results_wls.pvalues, 4)})\n",
    "print(f'Regression Table (Non-Robust SE): \\n{table_default}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "expected-operation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression Table (Refined White SE): \n",
      "                      Betas  Standarde Errors  t Statistics  p Value\n",
      "Intercept          -16.7025            2.2482       -7.4292   0.0000\n",
      "inc                  0.7404            0.0752        9.8403   0.0000\n",
      "I((age - 25) ** 2)   0.0175            0.0026        6.7650   0.0000\n",
      "male                 1.8405            1.3132        1.4015   0.1611\n",
      "e401k                5.1883            1.5743        3.2955   0.0010\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Robust results (refined White SE)\n",
    "results_white = reg_wls.fit(cov_type = 'HC3')\n",
    "\n",
    "# Print regression table\n",
    "table_white = pd.DataFrame({'Betas': round(results_white.params, 4),\n",
    "                     'Standarde Errors': round(results_white.bse, 4),\n",
    "                     't Statistics': round(results_white.tvalues, 4),\n",
    "                     'p Value': round(results_white.pvalues, 4)})\n",
    "print(f'Regression Table (Refined White SE): \\n{table_white}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unable-release",
   "metadata": {},
   "source": [
    "The assumption made in Example 8.6 that the variance is proportional to a regressor is usually hard to justify. Typically, we don't know the variance function and have to estimate it. This feasible GLS (FGLS) estimator replaces the (allegedly) known variance function with an estimated one.\n",
    "\n",
    "We can estiate the relation between variance and regressors using a linear regression of the log of the squared residuals from an initial OLS regression $log(\\hat{u}^2)$ as the dependent variable. Wooldridge (2019, Section 8.4) suggests two versions for the selection of regressors:\n",
    "\n",
    "- the regressors $x_1, x_2, ... x_k$ from the original model similar to the BP test.\n",
    "- $\\hat{y}$ and $\\hat{y}^2$ from the original model similar to the White test.\n",
    "\n",
    "As the estimated error variance, we can use $exp(\\hat{log(\\hat{u}^2}))$. Its inverse can then be used as a weight in WLS estimation.\n",
    "\n",
    "#### Woodridge, Example 8.7: Demand for Cigarettes\n",
    "\n",
    "In this example we study the relationship between daily cigarette consumption **cigs**, individual characteristics, and restaurant smoking restrictions **restaurn**. After the initial OLS regression, a BP test is performed which clearly rejects homoscedasticity (see previous section for the BP test). After the regression of log squared residuals on the regressors, the FGLS weights are calculated and used in the WLS regression. See Wooldridge (2019) for a discussion of the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "olympic-taxation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import wooldridge as woo\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import patsy as pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "chicken-solution",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data set 'smoke'\n",
    "smoke = woo.dataWoo('smoke')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bacterial-chorus",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression Table (OLS): \n",
      "                  Betas  Standarde Errors  t Statistics  p Value\n",
      "Intercept       -3.6398           24.0787       -0.1512   0.8799\n",
      "np.log(income)   0.8803            0.7278        1.2095   0.2268\n",
      "np.log(cigpric) -0.7509            5.7733       -0.1301   0.8966\n",
      "educ            -0.5015            0.1671       -3.0016   0.0028\n",
      "age              0.7707            0.1601        4.8132   0.0000\n",
      "I(age ** 2)     -0.0090            0.0017       -5.1765   0.0000\n",
      "restaurn        -2.8251            1.1118       -2.5410   0.0112\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# OLS regression \n",
    "reg_ols = smf.ols(formula = 'cigs ~ np.log(income) + np.log(cigpric) +'\n",
    "                 'educ + age + I(age**2) + restaurn',\n",
    "                 data = smoke)\n",
    "results_ols = reg_ols.fit()\n",
    "\n",
    "# Print regression table\n",
    "table_ols = pd.DataFrame({'Betas': round(results_ols.params, 4),\n",
    "                     'Standarde Errors': round(results_ols.bse, 4),\n",
    "                     't Statistics': round(results_ols.tvalues, 4),\n",
    "                     'p Value': round(results_ols.pvalues, 4)})\n",
    "print(f'Regression Table (OLS): \\n{table_ols}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "lightweight-tragedy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BP Test Statistic: 32.25841908120112\n",
      "\n",
      "BP Test p-value: 1.4557794830279539e-05\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# BP test\n",
    "y, X = pt.dmatrices('cigs ~ np.log(income) + np.log(cigpric) + educ +'\n",
    "                   'age + I(age**2) + restaurn',\n",
    "                   data = smoke, return_type = 'dataframe')\n",
    "result_bp = sm.stats.diagnostic.het_breuschpagan(results_ols.resid, X)\n",
    "bp_statistic = result_bp[0]\n",
    "bp_pval = result_bp[1]\n",
    "print(f'BP Test Statistic: {bp_statistic}\\n')\n",
    "print(f'BP Test p-value: {bp_pval}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "deadly-headline",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression Table (FGLS): \n",
      "                  Betas  Standarde Errors  t Statistics  p Value\n",
      "Intercept       -1.9207            2.5630       -0.7494   0.4538\n",
      "np.log(income)   0.2915            0.0775        3.7634   0.0002\n",
      "np.log(cigpric)  0.1954            0.6145        0.3180   0.7506\n",
      "educ            -0.0797            0.0178       -4.4817   0.0000\n",
      "age              0.2040            0.0170       11.9693   0.0000\n",
      "I(age ** 2)     -0.0024            0.0002      -12.8931   0.0000\n",
      "restaurn        -0.6270            0.1183       -5.2982   0.0000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# FGLS (estimation of the variance function)\n",
    "smoke['logu2'] = np.log(results_ols.resid ** 2)\n",
    "reg_fgls = smf.ols(formula = 'logu2 ~ np.log(income) + np.log(cigpric) +'\n",
    "                  'educ + age + I(age**2) + restaurn', data = smoke)\n",
    "results_fgls = reg_fgls.fit()\n",
    "\n",
    "# Print regression table\n",
    "table_fgls = pd.DataFrame({'Betas': round(results_fgls.params, 4),\n",
    "                     'Standarde Errors': round(results_fgls.bse, 4),\n",
    "                     't Statistics': round(results_fgls.tvalues, 4),\n",
    "                     'p Value': round(results_fgls.pvalues, 4)})\n",
    "print(f'Regression Table (FGLS): \\n{table_fgls}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "broken-executive",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression Table (WLS): \n",
      "                  Betas  Standarde Errors  t Statistics  p Value\n",
      "Intercept        5.6355           17.8031        0.3165   0.7517\n",
      "np.log(income)   1.2952            0.4370        2.9639   0.0031\n",
      "np.log(cigpric) -2.9403            4.4601       -0.6592   0.5099\n",
      "educ            -0.4634            0.1202       -3.8570   0.0001\n",
      "age              0.4819            0.0968        4.9784   0.0000\n",
      "I(age ** 2)     -0.0056            0.0009       -5.9897   0.0000\n",
      "restaurn        -3.4611            0.7955       -4.3508   0.0000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# FGLS (WLS)\n",
    "wls_weight = list(1 / np.exp(results_fgls.fittedvalues))\n",
    "reg_wls = smf.wls(formula = 'cigs ~ np.log(income) + np.log(cigpric) + '\n",
    "                  'educ + age + I(age**2) + restaurn', \n",
    "                  weights = wls_weight, data = smoke)\n",
    "results_wls = reg_wls.fit()\n",
    "\n",
    "# Print regression table\n",
    "table_wls = pd.DataFrame({'Betas': round(results_wls.params, 4),\n",
    "                     'Standarde Errors': round(results_wls.bse, 4),\n",
    "                     't Statistics': round(results_wls.tvalues, 4),\n",
    "                     'p Value': round(results_wls.pvalues, 4)})\n",
    "print(f'Regression Table (WLS): \\n{table_wls}\\n')"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
