{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "statutory-green",
   "metadata": {},
   "source": [
    "## Regression Inference and OLS Asymptotics\n",
    "\n",
    "In this notebook, we are going to study and demonstrate the use of *Python* to perform **statistical inference** to test our regression models. We are also going to explore the **Asymptotic Theory** and understand how it allows us to relax some assumptions needed to derive the sampling distribution of estimators if the sample is size is large enough.\n",
    "\n",
    "**Topics:**\n",
    "\n",
    "1. The *t* Test\n",
    "2. Confidence Intervals\n",
    "3. Linear Restrictions: *F* Tests\n",
    "4. Simulation Exercises\n",
    "5. LM Test\n",
    "\n",
    "Section 4.1 of Wooldridge (2019) adds assumption MLR.6 (normal distribution of the error term) to the previous assumptions MLR.1 through MLR.5. Together, these assumptions consitute the classical linear model (CLM).\n",
    "\n",
    "The main additional result we get from this assumption is stated in Theorem 4.1: The OLS parameter estimators are normally distributed (conditional on the regressors $x_1, x_2, ..., x_k$). The benefit of this result is that it allows us to do statistical inference similar to the approaches discussed the simple estimator of the mean of a normally distributed random variable.\n",
    "\n",
    "### 1. The *t* Test\n",
    "\n",
    "After the sign and magnitude of the estimated parameters, empirical resarch typically pays most attention to the results of *t* tests discussed in this section.\n",
    "\n",
    "#### General Setup\n",
    "\n",
    "An important type of hypotheses we are often interested in is of the form\n",
    "\n",
    "$$H_0: \\beta_j = a_j$$\n",
    "\n",
    "where $a_j$ is some given number, very often, $a_j$ = 0. For the most common cast of two-tailed tests, the alternative hypothesis is \n",
    "\n",
    "$$H_1: \\beta_j \\neq a_j$$\n",
    "\n",
    "and for one-tailed tests it is either one of\n",
    "\n",
    "$$H_1: \\beta_j > a_j$$\n",
    "\n",
    "or \n",
    "\n",
    "$$H_1: \\beta_j < a_j$$\n",
    "\n",
    "These hypotheses can be conveniently tested using a *t* test which is based on the test statistic\n",
    "\n",
    "$$t = \\frac{\\hat{\\beta}_j - a_j}{se(\\hat{\\beta}_j)}$$\n",
    "\n",
    "If $H_0$ is in fact true and the CLM assumptions holds, then this statistic has a t distribution with *n - k - 1* degree of freedom.\n",
    "\n",
    "#### Standard Case\n",
    "\n",
    "Very often, we want to test whether there is any relation at all between the dependent variable *y* and a regressor $x_j$ and do not want to impose a sign on the partial effect *a priori*. This is a mission for the standard two-sided *t* test with the hypothetical value $a_j$ = 0, so\n",
    "\n",
    "$$H_0: \\beta_j = 0$$\n",
    "\n",
    "$$H_1: \\beta_j \\neq 0$$\n",
    "\n",
    "$$t_{\\hat{\\beta}_j} = \\frac{\\hat{\\beta}_j}{se(\\hat{\\beta}_j)}$$\n",
    "\n",
    "The subscript on the *t* statistic indicates that this is **the** *t* value for $\\hat{\\beta}_j$ for this frequent version of the test. Under $H_0$, it has the *t* distribution with *n - k - 1* degree of freedom implying that the probability that $|t_{\\hat{\\beta}_j}| > c$ is equal to $\\alpha$ if *c* is the $1 - \\frac{\\alpha}{2}$ quantile of this distribution. If $\\alpha$ is our significance level (e.g. $\\alpha = 5\\%$), then we reject $H_0$ if $|t_{\\hat{\\beta}_j}| > c$ in our sample. For the typical significance level $\\alpha = 5\\%$, the critical value *c* will be around 2 for reasonable large degrees of freedom and approach the counterpart of 1.96 from the standard normal distribution in very large samples.\n",
    "\n",
    "The *p* value indicates the smallest value of the significance level $\\alpha$ for which we would still reject $H_0$ using our sample. So it is the probability for a random variable *T* with the respective *t* distribution that |*T*| > $|t_{\\hat{\\beta}_j}|$ where $t_{\\hat{\\beta}_j}$ is the value of the *t* statistic in our particular sample. In our two-tailed test, it can be calculated as\n",
    "\n",
    "$$p_{\\hat{\\beta}_j} = 2 \\cdot F_{t_{n-k-1}} \\cdot (-|t_{\\hat{\\beta}_j}|)$$\n",
    "\n",
    "where $F_{t_{n-k-1}} (\\cdot)$ is the CDF of the *t* distribution with *n - k - 1* degree of freedom. If our software provides us with the relevant *p* values, they are easy to use: We reject $H_0$ if $p_{\\hat{\\beta}_j} \\leq \\alpha$.\n",
    "\n",
    "Since this standard case of a *t* test is so common, **statsmodels** provides us with the relevant *t* and *p* values directly in the **summary** of the estimation results we already saw in the previous notebooks. The regression table includes for all regressors and the intercept:\n",
    "\n",
    "- parameter estimates and standard errors\n",
    "- test statistics $t_{\\hat{\\beta}_j}$ in column **t**\n",
    "- respective *p* values $p_{\\hat{\\beta}_j}$ in the colmun **P>|t|**\n",
    "- respective 95% confidence interval in columns **[0.025 and 0.975]**\n",
    "\n",
    "#### Wooldridge, Example 4.3: Determinants of College GPA\n",
    "\n",
    "We have repeatedly used the data set *GPA1* in the previous notebooks. This example uses three regressors and estimates a regression model of the form.\n",
    "\n",
    "$$colGPA = \\beta_0 + \\beta_1 \\cdot hsGPA + \\beta_2 \\cdot ACT + \\beta_3 \\cdot skipped + u$$\n",
    "\n",
    "For the critical values of the *t* test, using the normal approximation instead of the exact *t* distribution with *n - k - 1* = 137 d.f. doesn't make much of a difference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ahead-mongolia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Modules\n",
    "import scipy.stats as stats\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "smart-condition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Critical Values by t Distribution: [1.97743121 2.61219198]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# CV for alpha = 5% and 1% using the t distribution with 137 d.f.\n",
    "alpha = np.array([0.05, 0.01])\n",
    "cv_t = stats.t.ppf(1 - alpha / 2, 137)\n",
    "print(f'Critical Values by t Distribution: {cv_t}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "indoor-headquarters",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Critical Values by Normal Distribution: [1.95996398 2.5758293 ]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# CV for alpha = 5% and 1% using the normal approximation\n",
    "cv_n = stats.norm.ppf(1 - alpha / 2)\n",
    "print(f'Critical Values by Normal Distribution: {cv_n}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "respected-sympathy",
   "metadata": {},
   "source": [
    "We presents the standard **summary** which directly contains all the information to test the hypotheses for all parameters. The *t* statistics for all coefficients excepts $\\beta_2$ are larger in absolute value than the *critical value* c = 2.61 (or c = 2.58 using the normal approximation) for $\\alpha$ = 1%. So we would reject $H_0$ for all usual significance levels. By construction, we draw the same conclusions from the *p* values.\n",
    "\n",
    "In order to confirm that **statsmodels** is exactly using the formulas of Wooldridge (2019). We next reconstruct the *t* and *p* values manually. We extract the coefficients (**params**) and standard errors (**bse**) from the regression results, and simply apply the $t_{\\hat{\\beta}_j}$ and $p_{\\hat{\\beta}_j}$ equations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exotic-bruce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Modules\n",
    "import scipy.stats as stats\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compressed-longitude",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data set gpa1\n",
    "gpa1 = woo.dataWoo('gpa1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flying-irish",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store and display results:\n",
    "reg = smf.ols(formula = 'colGPA ~ hsGPA + ACT + skipped', data = gpa1)\n",
    "results = reg.fit()\n",
    "print(f'Regression Summary: \\n{results.summary()}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neither-visitor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually confirm the formulas:\n",
    "\n",
    "# Extract coefficients and SE\n",
    "b = results.params\n",
    "se = results.bse\n",
    "\n",
    "# Reproduce t statistic\n",
    "tstat = b / se\n",
    "print(f't Statistics: \\n{tstatat}\\n')\n",
    "\n",
    "# Reproduce p value\n",
    "pval = 2 * stats.t.cdf(-abs(tstat), 137)\n",
    "print(f'P Value: \\n{pval}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "binding-burden",
   "metadata": {},
   "source": [
    "#### Other Hypotheses\n",
    "\n",
    "For a one-tailed test, the critical value *c* of the *t* test and the *p* values have to be adjsuted appropriately Wooldridge (2019) provides a general discussion in Section 4.2. For testing the null hypothesis $H_0: \\beta_j = a_j$, the tests for the three common alternative hypotheses are summarized in the following table.\n",
    "\n",
    "**One- and Two-tailed *t* Tests for $H_0: \\beta_j = a_j$**\n",
    "\n",
    "|  $H_1$:  |  $\\beta_j \\neq a_j$  |  $\\beta_j > a_j$  |  $\\beta_j < a_j$  |\n",
    "|  :---:  |  :---:  |  :---:  |  :---:  |\n",
    "|  *c* = quantile  |  $1 - \\frac{\\alpha}{2}$  |  $1 - \\alpha$  |  $1 - \\alpha$  |\n",
    "|  Reject $H_0$ if  |  $|t_{\\hat{\\beta}_j}| > c$  |  $\\hat{\\beta}_j > c$  |  $\\hat{\\beta}_j > c$  |\n",
    "|  *p* value  |  $2 \\cdot F_{t_{n - k - 1}} \\cdot (-|t_{\\hat{\\beta}_j}|)$  |  $F_{t_{n - k - 1}} \\cdot (-t_{\\hat{\\beta}_j})$  |  $F_{t_{n - k - 1}} \\cdot (-t_{\\hat{\\beta}_j})$  |\n",
    "\n",
    "Given the stardard regerssion output including the *p* value for two-sided tests $p_{\\hat{\\beta}_j}$, we can easily do one-sided *t* tests for the null hypothesis $H_0: \\beta_j = 0$ in two steps:\n",
    "\n",
    "* Is $\\hat{\\beta}_j$ positive (if $H_1: \\beta_j > 0$) or negative (if $H_1: \\beta_j < 0$)?\n",
    "- No -> Do not reject $H_0$ since this cannot be evidence against $H_0$.\n",
    "- Yes -> The relevent *p* value is half of the reported $p_{\\hat{\\beta}_j}$.\n",
    "- Reject $H_0$ if $p = \\frac{1}{2} p_{\\hat{\\beta}_j} < \\alpha$.\n",
    "\n",
    "#### Wooldridge, Example 4.1: Hourly Wage Equation\n",
    "\n",
    "We have already estimated the wage equation\n",
    "\n",
    "$$log(wage) = \\beta_0 + \\beta_1 \\cdot educ + \\beta_2 \\cdot exper + \\beta_3 \\cdot tenure + u$$\n",
    "\n",
    "Now we are ready to test $H_0: \\beta_2 > 0$. For the critical values of the *t* test, using the normal approximation instead of the exact *t* distribution with *n - k - 1* = 522 d.f. doesn't make any relevant difference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ranking-associate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Modules\n",
    "import scipy.stats as stats\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "previous-reasoning",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CV for alpha = 5% and 1% using the t distribution with 522 d.f.\n",
    "alpha = np.array([0.05, 0.01])\n",
    "cv_t = stats.t.ppf(1 - alpha, 522)\n",
    "print(f'Critical Values by t Distribution: {cv_t}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dependent-minimum",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CV for alpha = 5% and 1% using the normal approximation\n",
    "cv_n = stats.norm.ppf(1 - alpha)\n",
    "print(f'Critical Values by Normal Distribution: {cv_n}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "auburn-covering",
   "metadata": {},
   "source": [
    "In this example, we show the standard regression output. The reported *t* statistic for the parameter of *exper* is $t_{\\hat{\\beta}_2}$ = 2.391 which is larger than the critical value *c* = 2.33 for the significance level $\\alpha$ = 1%, so we reject $H_0$. By construction, we get the same answer from looking at the *p* value. Like always, the reported $p_{\\hat{\\beta}_j}$ value is for a two-sided test, so we have to divide it by 2. The resulting value $p = \\frac{0.017}{2} = 0.0085 < 0.01$, so we reject $H-0$ using an $\\alpha$ = 1% significance level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finite-governor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Modules\n",
    "import wooldridge as woo\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "raised-kidney",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data set 'wage1'\n",
    "wage1 = woo.dataWoo('wage1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "single-england",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the regression model and print the model summary\n",
    "reg = smf.ols(formula = 'np.log(wage) ~ educ + exper + tenure', data = wage1)\n",
    "results = reg.fit()\n",
    "print(f'Regression Summary Output: \\n{results}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convenient-wagner",
   "metadata": {},
   "source": [
    "### 2. Confidence Intervals\n",
    "\n",
    "We have already looked at confidence intervals (CI) for the mean of a normally distributed random variabel in the previous notebook. CI for the regression parameters are equally easy to construct and closely related to *t* test. Wooldridge (2019, Section 4.3) provides a succinct discussion. The 95% confidence interval for parameter $\\beta_j$ is simply.\n",
    "\n",
    "$$\\hat{\\beta}_j \\pm c \\cdot se(\\hat{\\beta}_j)$$\n",
    "\n",
    "where *c* is the same critical value for the two-sided *t* test using a significance level $\\alpha$ = 5%. Wooldridge (2019) shows examples of how to manually construct these CI.\n",
    "\n",
    "**statsmodels** provides the 95% confdience intervals for all parameters in the regression table. If you use the method **conf_int()** on the object with the regression results, you can compute other significance levels. Below example demonstrates the procedure.\n",
    "\n",
    "#### Wooldridge, Example 4.8: Model of R&D Expenditures\n",
    "\n",
    "We study the relationship between the R&D expenditures of a firm, its size, and the profit margin for a sample of 32 firms in the chemical industry. The regression equation is\n",
    "\n",
    "$$log(rd) = \\beta_0 +\\beta_1 \\cdot log(sales) + \\beta_2 \\cdot profmarg + u$$\n",
    "\n",
    "Here, we present the regression results as well as the 95% and 99% CI. See Wooldridge (2019) for the manual calculation of the CI and comments on the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "governing-stamp",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Modules\n",
    "import wooldridge as woo\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modern-excerpt",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data set 'rdchem'\n",
    "rdchem = woo.dataWoo('rdchem')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "individual-saint",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OLS regression\n",
    "reg = smf.ols(formula = 'np.log(rd) ~ np.log(sales) + profmarg', data = rdchem)\n",
    "results = reg.fit()\n",
    "print(f'Regression Summary Output: \\n{results}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "objective-performance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 95% and 99% Confidence Interval:\n",
    "ci95 = results.conf_int(0.05)\n",
    "ci99 = results.conf_int(0.01)\n",
    "\n",
    "print(f'95% Confidence Interval: {ci95}\\n')\n",
    "print(f'99% Confidence Interval: {ci99}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "saving-height",
   "metadata": {},
   "source": [
    "### 3. Linear Restrictions: *F* Tests\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distant-leadership",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiac-egypt",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "endless-wells",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "present-headquarters",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "union-isolation",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
